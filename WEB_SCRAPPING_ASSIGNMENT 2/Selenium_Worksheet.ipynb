{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687f960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da42e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79dec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "efba8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad099ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "85108ec2",
   "metadata": {},
   "source": [
    "     1. All the questions must be done in a single Jupyter notebook.\n",
    "     2. There should be proper comments in code.\n",
    "\n",
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape \n",
    "  the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "  1. First get the webpage https://www.naukri.com/\n",
    "  2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location' field\n",
    "  3. Then click the search button.\n",
    "  4. Then scrape the data for the first 10 jobs results you get.\n",
    "  5. Finally create a dataframe of the scraped data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5010c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41efb60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"21268cff2719e865b3b3187000c78ec0\", element=\"9c7c562c-f7e2-4ff3-8e8e-f82f039dfe15\")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT IN SEARCH OPTION 'DATA ANALYTICS' JOB_TITLE\n",
    "job= driver.find_element_by_class_name('suggestor-input')\n",
    "\n",
    "job.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e4b98fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"21268cff2719e865b3b3187000c78ec0\", element=\"8f93001f-a2f7-4d6c-8d65-487b7aab816f\")>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT 'BANGALORE ' LOCATION \n",
    "\n",
    "locate= driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "\n",
    "locate.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19091bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"21268cff2719e865b3b3187000c78ec0\", element=\"1e7b516c-51f4-4434-bf30-a6d02f5efdf3\")>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "\n",
    "search.click()                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f8ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffdd7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING 'JOB_TITLE' DATA\n",
    "\n",
    "# now we extract 'job_title' data from web element\n",
    "\n",
    "job = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "Job_title= []      # store job_title's all element in this  variable \n",
    "for i in job :\n",
    "    Job_title.append(i.text)\n",
    "    \n",
    "Job_title[2]\n",
    "\n",
    "job_title = Job_title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4f5de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BYJUS\n"
     ]
    }
   ],
   "source": [
    "#EXTRACTING 'COMPANY_NAME' DATA\n",
    "\n",
    "# # now we extract 'company_name' data from web element\n",
    "\n",
    "corp = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "Company_name = []      # store corp's elements in this  variable by run for loop\n",
    "for i in corp:\n",
    "    Company_name.append(i.text)\n",
    "    \n",
    "print(Company_name[2])\n",
    "len(Company_name)\n",
    "\n",
    "company_name= Company_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c22b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c59b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore/Bengaluru\n"
     ]
    }
   ],
   "source": [
    "#EXTRACTING 'LOCATION' DATA\n",
    "\n",
    "# # now we extract 'location' data from web element\n",
    "\n",
    "locat = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "Location = []      # store loacte's elements in this variable by run for_loop\n",
    "for i in locat:\n",
    "#    print(i.text)\n",
    "    Location.append(i.text)\n",
    "    \n",
    "print(Location[2])\n",
    "len(Location)\n",
    "\n",
    "location= Location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c99e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fda2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-5 Yrs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EXTRACTING 'EXPERIANCE' DATA\n",
    "\n",
    "# # now we extract 'experiance' data from web element\n",
    "\n",
    "exe = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "Experience = []      # store exe's elements in this variable by run ( for loop)\n",
    "for i in exe:\n",
    "    Experience.append(i.text)\n",
    "    \n",
    "print(Experience[2])\n",
    "\n",
    "experience= Experience[0:10]\n",
    "len(Experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aca957ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst/Senior Data Analyst</td>\n",
       "      <td>Meesho</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>BYJUS</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Business Analyst, Data Analytics &amp; Engi...</td>\n",
       "      <td>Artech Infosystems Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Navitas LLP</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Bangalore/Bengaluru, Serilingampally</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Management Analyst</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>cliqhr.com</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>manoramaONLINE</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, kerala</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                   Data Analyst/Senior Data Analyst   \n",
       "1                             Senior Data Analyst II   \n",
       "2                                       Data Analyst   \n",
       "3  Senior Business Analyst, Data Analytics & Engi...   \n",
       "4                              Clinical Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6                     Senior Data Management Analyst   \n",
       "7                     Senior Data Management Analyst   \n",
       "8                      Business Analyst/Data Analyst   \n",
       "9                                Senior Data Analyst   \n",
       "\n",
       "                   Company_name  \\\n",
       "0                        Meesho   \n",
       "1                      Flipkart   \n",
       "2                         BYJUS   \n",
       "3  Artech Infosystems Pvt. Ltd.   \n",
       "4                   Navitas LLP   \n",
       "5                       Walmart   \n",
       "6                   Wells Fargo   \n",
       "7                   Wells Fargo   \n",
       "8                    cliqhr.com   \n",
       "9                manoramaONLINE   \n",
       "\n",
       "                                            Location Experience  \n",
       "0                                Bangalore/Bengaluru    3-6 Yrs  \n",
       "1                                Bangalore/Bengaluru    3-6 Yrs  \n",
       "2                                Bangalore/Bengaluru    2-5 Yrs  \n",
       "3            Bangalore/Bengaluru\\n(WFH during Covid)    4-8 Yrs  \n",
       "4                       Bangalore/Bengaluru, Chennai    3-8 Yrs  \n",
       "5                                Bangalore/Bengaluru    4-7 Yrs  \n",
       "6               Bangalore/Bengaluru, Serilingampally   7-12 Yrs  \n",
       "7                                Bangalore/Bengaluru   8-13 Yrs  \n",
       "8  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   5-10 Yrs  \n",
       "9               Bangalore/Bengaluru, Chennai, kerala   5-10 Yrs  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Job_title':job_title,'Company_name':company_name,'Location':location,'Experience':experience})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e617f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a97c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "01f70ebf",
   "metadata": {},
   "source": [
    "Q2:  Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location field\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5206883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f126d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0ad008",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c3dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WE SELECT 'Data Scientist ' job_title by coding\n",
    "\n",
    "driver.find_element(By.CLASS_NAME,'suggestor-input').send_keys('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d54e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select 'BANGALORE ' Location  by coding\n",
    "\n",
    "driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input').send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb0db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We click the 'SEARCH' button by coding\n",
    "\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58e56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0183ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataiku Consultant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EXTRACTING 'JOB_TITLE ' FROM  WEB ELEMENTS\n",
    "\n",
    "job= driver.find_elements(By.XPATH, '//a[@class= \"title fw500 ellipsis\"]')\n",
    "\n",
    "Job_title= []\n",
    "for i in job:\n",
    "#    print(i.text)\n",
    "    Job_title.append(i.text)\n",
    "\n",
    "Job_title= Job_title[0:10]\n",
    "print(Job_title[2])\n",
    "len(Job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217a3fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wipro\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING  'COMPANY_NAME' DATA from web element\n",
    "\n",
    "company= driver.find_elements(By.XPATH, '//a[@class= \"subTitle ellipsis fleft\"]')\n",
    "\n",
    "company_name= []    #  store data in this variable by runing  for_loop\n",
    "for i in company:\n",
    "#    print(i.text)\n",
    "    company_name.append(i.text)\n",
    "\n",
    "company_name= company_name[0:10]\n",
    "print(company_name[0])\n",
    "len(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d567015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore/Bengaluru, Pune\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING  'lOCATION' DATA from web element\n",
    "\n",
    "locat= driver.find_elements(By.XPATH, '//li[@class= \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "LOCATION= []    #  store data in this variable by runing  for_loop\n",
    "for i in locat:\n",
    "#    print(i.text)\n",
    "    LOCATION.append(i.text)\n",
    "\n",
    "LOCATION= LOCATION[0:10]\n",
    "print(LOCATION[1])\n",
    "len(LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "489b3644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Principal - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                   Hiring For Senior Data Scientist   \n",
       "2                                 Dataiku Consultant   \n",
       "3                                     Data Scientist   \n",
       "4  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "5                 Data Scientist: Advanced Analytics   \n",
       "6                                 Research Scientist   \n",
       "7                         Principal - Data Scientist   \n",
       "8            Research and Development -AI/ML -(PhD )   \n",
       "9  Opportunity For Data Scientist - Female Candid...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "1                          Bangalore/Bengaluru, Pune   \n",
       "2                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "9  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "\n",
       "                      company_name  \n",
       "0                            Wipro  \n",
       "1  TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                            Wipro  \n",
       "3                Applied Materials  \n",
       "4                              PwC  \n",
       "5                              IBM  \n",
       "6                              IBM  \n",
       "7               Schneider Electric  \n",
       "8                              EXL  \n",
       "9                             PayU  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Job_title':Job_title,'Location':LOCATION,'company_name':company_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ed074",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c9b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3452d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ce8e5a69",
   "metadata": {},
   "source": [
    "Q3:  In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "     You have to use the location and salary filter.\n",
    "     You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "     You have to scrape the job-title, job-location, company name, experience required. \n",
    "    The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a1f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e205af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f238bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6bc4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT 'DATA SCIENTIST'  JOB title\n",
    "\n",
    "driver3.find_element_by_class_name('suggestor-input').send_keys('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a68413b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLICKING  SEARCH \n",
    "\n",
    "search= driver3.find_element_by_xpath('//div[@class= \"qsbSubmit\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cbee76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT 'DELHI/NCR'  JOB LOCATION\n",
    "\n",
    "loc= driver3.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559ac18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c82ab9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT SALARY 3-6 LAKH\n",
    "\n",
    "driver3.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "027c7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPING JOB_TITLE NAME\n",
    "\n",
    "title = driver3.find_elements_by_xpath('//a[@class= \"title fw500 ellipsis\"]')\n",
    "\n",
    "\n",
    "job_title= []\n",
    "for i in title:\n",
    "    #print(i.text)\n",
    "    job_title.append(i.text)\n",
    "job_title = job_title[10:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ca5c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping location and experience\n",
    "# same span class name of  location, experience \n",
    "\n",
    "expe= driver3.find_elements_by_xpath('//span[@class= \"ellipsis fleft fs12 lh16 \"]')\n",
    "\n",
    "data= []\n",
    "for i in expe:\n",
    "    #print(i.text)\n",
    "    data.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b75ffb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience= []\n",
    "location = []\n",
    "for n in range(26,56,3):\n",
    "    experience.append(data[n])\n",
    "for i in range(28,56,3):\n",
    "    location.append(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fd339a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = driver3.find_elements_by_xpath('//a[@class= \"subTitle ellipsis fleft\"]')\n",
    "\n",
    "company_name= []\n",
    "for i in corp:\n",
    "#    print(i.text)\n",
    "    company_name.append(i.text)\n",
    "company_name= company_name[10:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85d0bf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jobs Territory',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'Mount Talent Consulting Private Limited',\n",
       " 'Kellton Tech Solutions',\n",
       " 'Walking Tree Consultancy Services pvt Ltd',\n",
       " 'Shriram Automall',\n",
       " 'TeamPlus Staffing Solution Pvt Ltd',\n",
       " 'Nibha Infotech Private Limited',\n",
       " 'excellence',\n",
       " 'Smart work Consultants']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7999a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Jobs Territory</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kellton Tech Solutions</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Seniors</td>\n",
       "      <td>Walking Tree Consultancy Services pvt Ltd</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring || Data Scientist || North Delhi || 5.5...</td>\n",
       "      <td>Shriram Automall</td>\n",
       "      <td>Delhi / NCR(Netaji Subhash Place)</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dot Net Developer</td>\n",
       "      <td>Nibha Infotech Private Limited</td>\n",
       "      <td>Delhi / NCR, Gurgaon/Gurugram</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>excellence</td>\n",
       "      <td>Mumbai, New Delhi, Pune</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Scientist - Java/ Scala/ Apache...</td>\n",
       "      <td>Smart work Consultants</td>\n",
       "      <td>Noida</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                Data Scientist - Internet Jobs - II   \n",
       "1                                       Data Science   \n",
       "2                                       Data Science   \n",
       "3                                     Data Scientist   \n",
       "4                           Machine Learning Seniors   \n",
       "5  Hiring || Data Scientist || North Delhi || 5.5...   \n",
       "6                             Data scientist- Python   \n",
       "7                                  Dot Net Developer   \n",
       "8                                      Data Engineer   \n",
       "9  Associate Data Scientist - Java/ Scala/ Apache...   \n",
       "\n",
       "                                company_name  \\\n",
       "0                             Jobs Territory   \n",
       "1    Mount Talent Consulting Private Limited   \n",
       "2    Mount Talent Consulting Private Limited   \n",
       "3                     Kellton Tech Solutions   \n",
       "4  Walking Tree Consultancy Services pvt Ltd   \n",
       "5                           Shriram Automall   \n",
       "6         TeamPlus Staffing Solution Pvt Ltd   \n",
       "7             Nibha Infotech Private Limited   \n",
       "8                                 excellence   \n",
       "9                     Smart work Consultants   \n",
       "\n",
       "                                            location experience  \n",
       "0  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...    3-6 Yrs  \n",
       "1  Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...    2-5 Yrs  \n",
       "2  Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...    2-5 Yrs  \n",
       "3                                   Gurgaon/Gurugram    3-6 Yrs  \n",
       "4                  Hyderabad/Secunderabad, New Delhi    2-5 Yrs  \n",
       "5                  Delhi / NCR(Netaji Subhash Place)    4-9 Yrs  \n",
       "6                                   Gurgaon/Gurugram    3-6 Yrs  \n",
       "7                      Delhi / NCR, Gurgaon/Gurugram    3-8 Yrs  \n",
       "8                            Mumbai, New Delhi, Pune    4-9 Yrs  \n",
       "9                                              Noida    1-4 Yrs  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'job_title':job_title, 'company_name':company_name, 'location':location, 'experience':experience})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad5d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301afaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "bb61c183",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand, 2. Product Description, 3. Price\n",
    " \n",
    "To scrape the data you have to go through following steps:\n",
    " 1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it\n",
    "\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses\n",
    "\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49d85dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba339185",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe4ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "efde22b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"39cfdc0977b823cc17ec901be79635a1\", element=\"cb514171-7505-479b-b6c4-0ef6bc8db475\")>\n"
     ]
    }
   ],
   "source": [
    "# in search box fill 'sunglasses by coding'\n",
    "\n",
    "product= driver4.find_element(By.CLASS_NAME,'_3704LK')\n",
    "print(product)\n",
    "\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dfb3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click search bar \n",
    "\n",
    "search = driver4.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb2fcfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING 'SUNGLASSES BRAND_NAME' , 1-40 \n",
    "\n",
    "#\n",
    "\n",
    "brand= driver4.find_elements_by_class_name('_2WkVRV')\n",
    "\n",
    "Brand= []\n",
    "for i in brand:\n",
    "    Brand.append(i.text)\n",
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65c1a6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING ANOTHER 'SUNGLASSES BRAND_NAME' , FROM= 40-80 \n",
    "\n",
    "#\n",
    "\n",
    "brand1= driver4.find_elements_by_class_name('_2WkVRV')\n",
    "\n",
    "for i in brand1:\n",
    "    Brand.append(i.text)\n",
    "Brand= Brand[0:80]\n",
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83fdf654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING ANOTHER 'SUNGLASSES BRAND_NAME' , FROM= 80-100 \n",
    "\n",
    "#\n",
    "\n",
    "brand1= driver4.find_elements_by_class_name('_2WkVRV')\n",
    "\n",
    "for i in brand1:\n",
    "    Brand.append(i.text)\n",
    "Brand= Brand[0:100]\n",
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "446870e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "771b278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT PAGE FOR EXTRACT ANOTHER  40 TO 80 SUNGLASSES DATA\n",
    "\n",
    "#  we move to next page for EXTRACTING another ( 40 to 80 ) product data\n",
    "\n",
    "nex = driver4.find_element_by_xpath('//a[@class= \"_1LKTO3\"]')\n",
    "\n",
    "nex.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fc5c3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  We now move to next page for EXTRACTING another ( 80 to 100 ) product data\n",
    "\n",
    "nex = driver4.find_element_by_xpath('//a[@class= \"_1LKTO3\"]')\n",
    "\n",
    "nex.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b35fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fbfd2243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING ' PRODUCT DESCRIPTION ', 1-40\n",
    "\n",
    "\n",
    "descrip = driver4.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "Description= []\n",
    "for i in descrip:\n",
    "    Description.append(i.text)\n",
    "    \n",
    "len(Description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33518287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING  ANOTHER ' PRODUCT DESCRIPTION ', FROM 40-80\n",
    "\n",
    "\n",
    "descrip1 = driver4.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in descrip1:\n",
    "    Description.append(i.text)\n",
    "    \n",
    "len(Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e3c2d194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING  ANOTHER ' PRODUCT DESCRIPTION ', FROM 80-100\n",
    "\n",
    "\n",
    "descrip1 = driver4.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in descrip1:\n",
    "    Description.append(i.text)\n",
    "    \n",
    "len(Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "220ba272",
   "metadata": {},
   "outputs": [],
   "source": [
    "Description= Description[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ae2161a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING ' PRODUCT PRICE ' , 1-40\n",
    "\n",
    "\n",
    "p = driver4.find_elements_by_xpath('//div[@class= \"_30jeq3\"]')\n",
    "\n",
    "Price= []\n",
    "for i in p:\n",
    "    Price.append(i.text)\n",
    "    \n",
    "len(Price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20f6a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING  ANOTHER 'PRODUCT PRICE ' , FROM 40-80\n",
    "\n",
    "\n",
    "p1 = driver4.find_elements_by_xpath('//div[@class= \"_30jeq3\"]')\n",
    "\n",
    "for i in p1:\n",
    "    Price.append(i.text)\n",
    "    \n",
    "len(Price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "21af3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING  ANOTHER 'PRODUCT PRICE ' , FROM 80-100\n",
    "\n",
    "\n",
    "p1 = driver4.find_elements_by_xpath('//div[@class= \"_30jeq3\"]')\n",
    "\n",
    "for i in p1:\n",
    "    Price.append(i.text)\n",
    "    \n",
    "Price= Price[0:100]   \n",
    "len(Price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e0f68aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Over-sized ...</td>\n",
       "      <td>₹645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Polarized Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Mirrored Aviator Sunglasses (57)</td>\n",
       "      <td>₹242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price\n",
       "0        New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹264\n",
       "1        Elligator                UV Protection Round Sunglasses (54)  ₹315\n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (50)  ₹224\n",
       "3    VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...  ₹799\n",
       "4         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799\n",
       "..             ...                                                ...   ...\n",
       "95   VINCENT CHASE  UV Protection, Gradient Butterfly, Over-sized ...  ₹645\n",
       "96          AISLIN  Gradient, Toughened Glass Lens, UV Protection ...  ₹664\n",
       "97            SRPM           Polarized Aviator Sunglasses (Free Size)  ₹899\n",
       "98        Fastrack  by Lenskart Polarized, UV Protection Wayfarer ...  ₹949\n",
       "99  ROZZETTA CRAFT                   Mirrored Aviator Sunglasses (57)  ₹242\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Brand':Brand,'Description':Description, 'Price':Price})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552bdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682204aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73726de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e2a46f9c",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    " 1. First get the webpage https://www.flipkart.com/\n",
    " 2. Enter “iphone 11” in “Search” field . \n",
    " 3. Then click the search button.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    " 1. Rating,   2. Review summary,  3. Full review,  4. You have to scrape this data for first 100 reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1082fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6e3581f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9d4fc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WE SELECT ' IPHONE 11' IN SEARCH BOX BY PYTHON_CODING\n",
    "\n",
    "driver5.find_element_by_class_name('_3704LK').send_keys('iphone11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b0a39808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WE SELECT ' SEARCH_BAR' AND SEARCHING IPHONE 11 item,  by PYTHON_CODING\n",
    "\n",
    "\n",
    "driver5.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aa659f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone11 = driver5.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[3]/div/div/div/a/div[2]/div[1]/div[1]')\n",
    "iphone11.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619b57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b9b449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= driver5.find_elements(By.XPATH,'//div[@class= \"_3LWZlK _1BLPMq\"]')\n",
    "for i in x:\n",
    "    print(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb5363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc119cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1971cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "req= requests.get(\"https://www.flipkart.com/apple-iphone-11-purple-128-gb/p/itmb7ca0b05522ff?pid=MOBFWQ6BEHFXGXGB&lid=LSTMOBFWQ6BEHFXGXGBMVHGLV&marketplace=FLIPKART&q=iphone11&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=fc668551-2845-4b6e-bb5e-3059cc6c39db.MOBFWQ6BEHFXGXGB.SEARCH&ppt=hp&ppn=homepage&ssid=nq96d3h7zk0000001657629759553&qH=d6db477051465f9a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0cef0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(req.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0448b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simply awesome\n",
      "Perfect product!\n",
      "Best in the market!\n",
      "Highly recommended\n",
      "Worth every penny\n",
      "Fabulous!\n",
      "Great product\n",
      "Worth every penny\n",
      "Good choice\n",
      "Highly recommended\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('p',class_ = '_2-N8zT'):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7743de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. INCOMPLETE , DOES NOT SCRAPING DATA THROUGH SELENIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22908f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176ceaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9eb19e9e",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    " search field.\n",
    "  You have to scrape 4 attributes of each sneaker:\n",
    " 1. Brand,   2. Product Description,   3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2baf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976508cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5894ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE SELECT ' SNEAKERS' IN SEARCH BOX  BY PYTHON_CODING\n",
    "\n",
    "driver6.find_element_by_class_name('_3704LK').send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fcb47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WE SELECT ' SEARCH_BAR' AND SEARCHING SNEAKERS item, PYTHON_CODING\n",
    "\n",
    "driver6.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1693b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdd67fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting 'brand name' data of sneakers from  flipkart.com\n",
    "\n",
    "brand= driver6.find_elements_by_xpath('//div[@class= \"_2WkVRV\"]')\n",
    "\n",
    "Brand= []\n",
    "for i in brand:\n",
    "#    print(i.text)\n",
    "    Brand.append(i.text)\n",
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d67f104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes price' data from  flipkart\n",
    "\n",
    "p = driver6.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "Price= []\n",
    "for i in p:\n",
    "#    print(i.text)\n",
    "    Price.append(i.text)\n",
    "len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a37b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes description' data from  flipkart\n",
    "\n",
    "d = driver6.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "Description= []\n",
    "for i in d:\n",
    "#    print(i.text)\n",
    "    Description.append(i.text)\n",
    "len(Description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8970c90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes offer' data (1 to 40) from  flipkart\n",
    "\n",
    "a = driver6.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "offer= []\n",
    "for i in a:\n",
    "#    print(i.text)\n",
    "    offer.append(i.text)\n",
    "len(offer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3925f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93a22bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we move next page to extract another (40-80) shoes data\n",
    "\n",
    "driver6.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bac90275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting 'brand name'  (40 to 80) of sneakers from  flipkart.com\n",
    "\n",
    "brand= driver6.find_elements_by_xpath('//div[@class= \"_2WkVRV\"]')\n",
    "\n",
    "for i in brand:\n",
    "#    print(i.text)\n",
    "    Brand.append(i.text)\n",
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dabb5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes price'  (40 to 80) from  flipkart\n",
    "\n",
    "p = driver6.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in p:\n",
    "#    print(i.text)\n",
    "    Price.append(i.text)\n",
    "len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "573a77ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes description'  (40 to 80)  from  flipkart\n",
    "\n",
    "d = driver6.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "#for i in d:\n",
    "#    print(i.text)\n",
    "#   Description.append(i.text)\n",
    "len(Description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "699f0017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes offer'  (40 to 80) from  flipkart\n",
    "\n",
    "a = driver6.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "\n",
    "for i in a:\n",
    "#    print(i.text)\n",
    "    offer.append(i.text)\n",
    "len(offer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f421f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1959e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we move next page to extract another (80-100) shoes data\n",
    "\n",
    "driver6.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[4]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42e67911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting 'brand name' data (80 to 100) of sneakers from  flipkart.com\n",
    "\n",
    "brand= driver6.find_elements_by_xpath('//div[@class= \"_2WkVRV\"]')\n",
    "\n",
    "for i in brand:\n",
    "#    print(i.text)\n",
    "    Brand.append(i.text)\n",
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8318e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes price'  (80 to 100) from  flipkart\n",
    "\n",
    "p = driver6.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "for i in p:\n",
    "#    print(i.text)\n",
    "    Price.append(i.text)\n",
    "len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2319a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes description'  (80 to 100)  from  flipkart\n",
    "\n",
    "d = driver6.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "for i in d:\n",
    "#    print(i.text)\n",
    "   Description.append(i.text)\n",
    "len(Description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ff745ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ' Shoes offer'   (80 to 100) from  flipkart\n",
    "\n",
    "a = driver6.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "\n",
    "for i in a:\n",
    "#    print(i.text)\n",
    "    offer.append(i.text)\n",
    "len(offer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d64631",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336a2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174cacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ae079f79",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    " Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    " \n",
    " And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    " description, price of the shoe as shown in the below image.\n",
    " \n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8192093",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b5c352c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.find_element_by_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c6d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. INSPECT OPTION DOES NOT WORK \n",
    "\n",
    " over myntra.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b212d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59de70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666271b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9c20383d",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    " After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title, 2. Ratings, 3. Price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "63599e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cff16460",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f8f2f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fill 'laptop' to search box (amazon.com ) web portal\n",
    "\n",
    "driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input').send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "68c53745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we click now 'search' bar for getting  laptop information \n",
    "\n",
    "driver8.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "00b7f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select 'i7 processor'  option of laptop \n",
    "\n",
    "i7= driver8.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a/div/label/i')\n",
    "i7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5643ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data of 'Laptop's title ' on (amazon.com)  by coding\n",
    "\n",
    "tit= driver8.find_elements_by_xpath('//span[@class= \"a-size-medium a-color-base a-text-normal\"]')\n",
    "\n",
    "t1= []\n",
    "title= []\n",
    "for i in tit:\n",
    "    t1.append(i.text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9bda6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in t1:\n",
    "    title.append(n[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094861bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1b6b5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra= driver8.find_elements_by_xpath('//span[@class= \"a-icon-alt\"]')\n",
    "rating8= []\n",
    "for i in ra:\n",
    "    rating8.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89bd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e9aa8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "price = driver8.find_elements_by_xpath('//span[@class= \"a-price-whole\"]')\n",
    "\n",
    "Price= []\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "73bb8264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion 14 12th</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim</td>\n",
       "      <td>75,203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hp Pavilion X360 11T</td>\n",
       "      <td>84,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy Book2</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG Gram 17 Intel Evo</td>\n",
       "      <td>95,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkBook 13s</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS Vivobook 15, 15</td>\n",
       "      <td>57,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkBook 15</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS Zenbook 14 OLED</td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title     Price\n",
       "0  HP Pavilion 14 12th     86,990\n",
       "1  ASUS TUF Gaming F15     89,990\n",
       "2  Lenovo IdeaPad Slim     75,203\n",
       "3  Hp Pavilion X360 11T    84,479\n",
       "4  Samsung Galaxy Book2    79,990\n",
       "5  LG Gram 17 Intel Evo    95,999\n",
       "6  Lenovo ThinkBook 13s    89,990\n",
       "7  ASUS Vivobook 15, 15    57,800\n",
       "8  Lenovo ThinkBook 15     86,990\n",
       "9  ASUS Zenbook 14 OLED  1,04,990"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df= pd.DataFrame({'Title':title, 'Price':Price, })\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be49a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797e661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd95f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "69ad8a5a",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location.\n",
    "  You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be\n",
    "  done in following steps:\n",
    " 1. First get the webpage https://www.ambitionbox.com/\n",
    " 2. Click on the Job option as shown in the image\n",
    " 3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    " 4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    " 5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    " 6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907978fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d235ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b0eb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f741c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a177c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT 'JOBS' OPTION on (ambitionbox.com) web portal, by coding\n",
    "\n",
    "driver9.find_element(By.XPATH,'/html/body/div[1]/nav/nav/a[6]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "401b1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and again we choose 'Data Scientist' designation  on web_portal, by coding\n",
    "\n",
    "job= driver9.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "\n",
    "job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b863a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click search bar for Data_Scientist job on web_portal, by python_coding \n",
    "\n",
    "driver9.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3091baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select Location 'Noida' fo Data_scientist job\n",
    "\n",
    "locat= driver9.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "locat.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd4da063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally  click option 'Noida' to search data_scientist job in Noida\n",
    "\n",
    "search= driver9.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55149e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eda4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting 'Company_name ' data of Data_scientist job in Noida\n",
    "\n",
    "corp = driver9.find_elements(By.XPATH,'//p[@class= \"company body-medium\"]')\n",
    "\n",
    "company9= []\n",
    "for i in corp:\n",
    "    company9.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4324da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting ' Rating of the company' data of Data_scientist job in Noida\n",
    "\n",
    "r = driver9.find_elements(By.XPATH,'//span[@class= \"body-small\"]')\n",
    "\n",
    "rating= []\n",
    "for i in r:\n",
    "    rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e34d5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data of  'No. of days ago when job was posted'   of Data_scientist job in Noida\n",
    "\n",
    "pos = driver9.find_elements(By.XPATH,'//span[@class= \"body-small-l\"]')\n",
    "\n",
    "posted= []\n",
    "for i in pos:\n",
    "    posted.append(i.text)\n",
    "    \n",
    "posted= posted[0:20:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae1c271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of Question9_solution\n",
    "\n",
    "Q9_DF= pd.DataFrame({'Company_Name':company9, 'Rating':rating, 'posted':posted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2939454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InfoEdge India Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latent bridge</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Careerera</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Careernet Consulting</td>\n",
       "      <td>3.9</td>\n",
       "      <td>28d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company_Name Rating   posted\n",
       "0  Optum Global Solutions (India) Private Limited    4.1   8d ago\n",
       "1                   GENPACT India Private Limited    4.0  15d ago\n",
       "2                         Dew Solutions Pvt. Ltd.    4.3   6d ago\n",
       "3                             InfoEdge India Ltd.    3.9  13d ago\n",
       "4                         Info Edge India Limited    3.9  14d ago\n",
       "5                         Info Edge India Limited    3.9  14d ago\n",
       "6                                   Latent bridge    4.5  14d ago\n",
       "7                                       Careerera    3.8   1d ago\n",
       "8                            Careernet Consulting    3.9  28d ago\n",
       "9                     Acidaes Solutions Pvt. Ltd.    3.8  14d ago"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q9_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fdc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fa966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb31ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ae47f8f9",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "    You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "  1. First get the webpage https://www.ambitionbox.com/\n",
    "  2. Click on the salaries option as shown in the image.\n",
    "  3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” \n",
    "   and then click on “Data Scientist”.\n",
    "   \n",
    "   4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "  salary, minimum salary, maximum salary, experience required.\n",
    "  5. Store the data in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b55ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10 = webdriver.Chrome(r'C:\\Users\\acer\\INTERNSHIP_WORSHEET\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5026520",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.ambitionbox.com/'\n",
    "\n",
    "driver10.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14cd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 'SALARY'  option and move next page , by python_coding not manually\n",
    "\n",
    "salary= driver10.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73f1dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT 'DATA SCIENTIST' in JOB_PROFILE SEARCH BOX ,  by python_coding\n",
    "\n",
    "job= driver10.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f2a68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7659bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING  'COMPANY_NAME' DATA for data_scientist job FROM WEB_ELEMENTS, by coding not manually\n",
    "\n",
    "com = driver10.find_elements_by_xpath('//div[@class= \"company-info\"]')\n",
    "\n",
    "corp=[]\n",
    "for i in com:\n",
    "#    print(i.text.split('\\n')[0])\n",
    "    corp.append(i.text.split('\\n')[0])\n",
    "    \n",
    "company_name= corp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "814ab76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING 'NUMBER OF SALARIES' FROM WEB ELEMENTS , by coding \n",
    "\n",
    "t=driver10.find_elements_by_xpath('//span[@class=\"datapoints\"]')\n",
    "\n",
    "No_salary= []\n",
    "for i in t:\n",
    "    No_salary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b78c0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING  'EXPERIENCE' DATA for data_scientist job  FROM WEB_ELEMENTS, by coding not manually\n",
    "\n",
    "\n",
    "exep = driver10.find_elements_by_xpath('//div[@class= \"sbold-list-header\"]')\n",
    "\n",
    "experience= []\n",
    "total_salary= []\n",
    "for i in exep:\n",
    "#    print(i.text.split('(')[0])\n",
    "    experience.append(i.text.split('(')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "50ee2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACTING  'AVERAGE_SALARY' DATA for data_scientist job FROM WEB_ELEMENTS, by coding not manually\n",
    "\n",
    "t_salary = driver10.find_elements_by_xpath('//p[@class= \"averageCtc\"]')\n",
    "\n",
    "average_salary = []\n",
    "for i in t_salary:\n",
    "#    print(i.text)\n",
    "    average_salary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d8a4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXTRACTING  'MINIMUM_SALARY' AND 'MAXIMUM_SALARY'  DATA  FROM  WEB_ELEMENTS, by coding not manually\n",
    "\n",
    "\n",
    "mi_salary = driver10.find_elements_by_xpath('//div[@class= \"value body-medium\"]')\n",
    "\n",
    "a=[]\n",
    "\n",
    "min_salary= []\n",
    "max_salary= []\n",
    "for i in mi_salary:\n",
    "#    print(i.text.split('\\n'))\n",
    "    \n",
    "    a.append(i.text)\n",
    "for n in range(0,20,2):\n",
    "    min_salary.append(a[n])\n",
    "for n in range(1,20,2):    \n",
    "    max_salary.append(a[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944aa37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8dfa4fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Number_of_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>₹ 30.6L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 36.0L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "      <td>(based on 12 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>₹ 20.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>(based on 33 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>₹ 16.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2 yrs experience</td>\n",
       "      <td>(based on 15 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.5L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>(based on 32 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>(based on 21 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>(based on 89 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>(based on 51 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>(based on 57 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 13.2L</td>\n",
       "      <td>₹ 7.6L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>(based on 21 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>₹ 12.8L</td>\n",
       "      <td>₹ 7.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>(based on 69 salaries)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company_name Average_Salary Min_Salary Max_Salary  \\\n",
       "0            Walmart        ₹ 30.6L    ₹ 25.0L    ₹ 36.0L   \n",
       "1           Ab Inbev        ₹ 20.8L    ₹ 15.0L    ₹ 26.2L   \n",
       "2                 ZS        ₹ 16.7L    ₹ 11.0L    ₹ 22.0L   \n",
       "3              Optum        ₹ 15.9L    ₹ 11.0L    ₹ 22.5L   \n",
       "4       Reliance Jio        ₹ 15.7L     ₹ 5.6L    ₹ 26.2L   \n",
       "5  Fractal Analytics        ₹ 15.5L    ₹ 10.0L    ₹ 23.0L   \n",
       "6    Tiger Analytics        ₹ 14.8L     ₹ 9.0L    ₹ 20.0L   \n",
       "7       UnitedHealth        ₹ 14.0L     ₹ 8.3L    ₹ 21.1L   \n",
       "8        EXL Service        ₹ 13.2L     ₹ 7.6L    ₹ 21.0L   \n",
       "9           Deloitte        ₹ 12.8L     ₹ 7.0L    ₹ 25.0L   \n",
       "\n",
       "            Experience        Number_of_Salary  \n",
       "0    3 yrs experience   (based on 12 salaries)  \n",
       "1  3-4 yrs experience   (based on 33 salaries)  \n",
       "2    2 yrs experience   (based on 15 salaries)  \n",
       "3  3-4 yrs experience   (based on 32 salaries)  \n",
       "4  3-4 yrs experience   (based on 21 salaries)  \n",
       "5  2-4 yrs experience   (based on 89 salaries)  \n",
       "6  2-4 yrs experience   (based on 51 salaries)  \n",
       "7  2-4 yrs experience   (based on 57 salaries)  \n",
       "8  3-4 yrs experience   (based on 21 salaries)  \n",
       "9  2-4 yrs experience   (based on 69 salaries)  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Make dataframe of Question10_solution\n",
    "\n",
    "\n",
    "pd.DataFrame({'Company_name':company_name , 'Average_Salary':average_salary,'Min_Salary':min_salary,\n",
    "              'Max_Salary':max_salary,'Experience':experience,'Number_of_Salary':No_salary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
