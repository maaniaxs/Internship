{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df64edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4451ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7f964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "req= requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b36f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3a25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(req.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a python program to display all the header tags from wikipedia.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfdab39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "From today's featured list\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('span', class_ = 'mw-headline' ):\n",
    "    print(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf046e36",
   "metadata": {},
   "source": [
    "# Q2.= Write  a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "           and make DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56817bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "req3=requests.get('https://www.imdb.com/chart/top/?ref_=nv_mv_250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a1e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(req3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8ce1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scrapping movie's name data\n",
    "full=[]\n",
    "for i in soup2.find_all('a'):\n",
    "    l=i.text.split()\n",
    "    k=''.join(l)\n",
    "    #print(k)\n",
    "    full.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16411750",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=full[52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f116e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scrapping movie's name data\n",
    "moviename=[]\n",
    "for i in range(0,200,2):\n",
    "    ll=mm[i]\n",
    "    #print(ll)\n",
    "    moviename.append(ll)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18891e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moviename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c68d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping movie's year data\n",
    "year=[]\n",
    "for i in soup2.find_all('span', class_= 'secondaryInfo'):\n",
    "    l=i.text\n",
    "    p=l[1:-1]\n",
    "    year.append(p)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48404f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year=year[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab489e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   scrapping movie's rating data\n",
    "rate= []\n",
    "rating=[]\n",
    "n=0\n",
    "for i in soup2.find_all('td', class_= 'ratingColumn imdbRating'):\n",
    "    if n<=99:\n",
    "    #print(i.text)\n",
    "        rate.append(i.text)\n",
    "        l=rate[n][1:4]\n",
    "        rating.append(l)\n",
    "        \n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a09790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d04f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c3a7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic= {'Movies_name':moviename, 'Rating': rating, 'Year':Year}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfa12398",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_top_100_movies=pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acb20d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheShawshankRedemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheGodfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheDarkKnight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheGodfatherPartII</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Movies_name Rating  Year\n",
       "0  TheShawshankRedemption    9.2  1994\n",
       "1            TheGodfather    9.2  1972\n",
       "2           TheDarkKnight    9.0  2008\n",
       "3      TheGodfatherPartII    9.0  1974"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_top_100_movies.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "098d6f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_top_100_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5eaff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('https://raw.githubusercontent.com/maaniaxs/Internship/main/Worksheet_2/imdb_top_100_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  complete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5efd6741",
   "metadata": {},
   "source": [
    "Q3=  Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "405072e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page3= requests.get('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae919db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup3=BeautifulSoup(page3.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49f78027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scraping imdb top 100 movies release 'year' Data\n",
    "year= []\n",
    "y=[]\n",
    "n=0\n",
    "for i in soup3.find_all('span',class_= 'secondaryInfo'):\n",
    "    if n<100:\n",
    "        \n",
    "        #print(i.text)\n",
    "        y.append(i.text)\n",
    "        l=y[n][1:-1]\n",
    "        year.append(l)\n",
    "    n+=1\n",
    "    #print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b7f60a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ba4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scraping imdb top 100 movies 'Name' Data\n",
    "\n",
    "mov=[]\n",
    "for i in soup3.find_all('a'):\n",
    "    #print(i.text)\n",
    "    mov.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8e1f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=mov[58:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "701f42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scraping imdb top 100 movies 'Name' Data\n",
    "\n",
    "indian_movies= []\n",
    "for i in range(0,200,2):\n",
    "    #print(movie[i])\n",
    "    indian_movies.append(movie[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf336546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "##  scraping imdb top 100 movies 'Rating' Data\n",
    "\n",
    "r= []\n",
    "rating= []\n",
    "n=0\n",
    "for i in soup3.find_all('td', class_= 'ratingColumn imdbRating'):\n",
    "    if n<=99:\n",
    "        \n",
    "        r.append(i.text)\n",
    "        l=r[n][1:4]\n",
    "        rating.append(l)\n",
    "    n+=1\n",
    "print(len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472bacc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c932dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic3= {'Indian_movies':indian_movies, 'Year':year, 'Rating':rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08a83715",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_top_indian_movies= pd.DataFrame(dic3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d16a283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_top_indian_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca15deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('https://raw.githubusercontent.com/maaniaxs/Internship/main/Worksheet_2/imdb_top_indian_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### complete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46e2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "5ed5c8b1",
   "metadata": {},
   "source": [
    "Q4=  Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "      from https://presidentofindia.nic.in/former-presidents.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8d6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "page4= requests.get('https://presidentofindia.nic.in/former-presidents.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af1c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup4= BeautifulSoup(page4.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9446c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  scrapping data of \" president's term of oofice \"\n",
    "\n",
    "term= []\n",
    "for i in soup4.find_all('p'):\n",
    "    #print(i.text)\n",
    "    term.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4e9c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=term[0:7:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ebef403",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=term[7:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe434fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_of_office= k+l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b24ab752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Term of Office: 25 July, 2002 to 25 July, 2007 '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_of_office[2]   #  checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4929916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c443ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shri K. R. Narayanan (1920 - 2005)\n"
     ]
    }
   ],
   "source": [
    "##  scrapping '' president name ''\n",
    "\n",
    "president_name= []\n",
    "for i in soup4.find_all('h3'):\n",
    "    #print(i.text)\n",
    "    president_name.append(i.text)\n",
    "print(president_name[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a21a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  complete  Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b357689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "2831cb68",
   "metadata": {},
   "source": [
    "Q5. 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdbccb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page5 = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a955ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup5= BeautifulSoup(page5.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cfc3388",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  a)  TOP 10 ODI TEAM RANKING NAMES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dca2c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping top ten 'ODI CRICKET TEAM NAME'\n",
    "TEAM= []\n",
    "for i in soup5.find_all('span', class_='u-hide-phablet' ):\n",
    "    K=i.text\n",
    "    TEAM.append(K)\n",
    "MEN_ODI_TEAM = TEAM[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecddcd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'India'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEN_ODI_TEAM[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9b0855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPPING ODI CRICKET TEAM MATCHES & POINTS\n",
    "m= []\n",
    "for i in soup5.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "    m.append(i.text)\n",
    "Matches= m[0:20:2]\n",
    "points = m[1:21:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f2227b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches list= ['22', '19', '22', '23', '19', '24', '29', '32', '18', '20']\n",
      "points list = ['2,756', '2,005', '2,304', '2,325', '1,872', '2,275', '2,658', '2,306', '1,238', '1,083']\n"
     ]
    }
   ],
   "source": [
    "print('matches list=',Matches)\n",
    "print('points list =',points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "352c353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCRAPPING \" MEN_ODI_TEAM CRICKET TEAM RATING \"\"\n",
    "\n",
    "rating= []\n",
    "for i in soup5.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    r= i.text\n",
    "    rating.append(r)\n",
    "Rating= rating[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e581bced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['125', '106', '105', '101', '99', '95', '92', '72', '69', '54']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b70c9c95",
   "metadata": {},
   "source": [
    "# b.  Top 10 ODI Batsmen along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1359beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "page5_ = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup55= BeautifulSoup(page5_.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3af04d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###  c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "player= []\n",
    "for i in soup55.find_all('tr',class_='table-body'):\n",
    "    #print(i.text.split())\n",
    "    player.append(i.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e1f9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_odi_bowler= []\n",
    "top_bowler_rating = []\n",
    "top_bowler_team = []\n",
    "p=player[9:18]\n",
    "for i in range(len(p)):\n",
    "    k=p[i][2:-2]\n",
    "    top_odi_bowler.append(k)\n",
    "    #print(p[i][-2])\n",
    "    k1= p[i][-2]\n",
    "    top_bowler_team.append(k1)\n",
    "    #print(p[i][-1])\n",
    "    k2= p[i][-1]\n",
    "    top_bowler_rating.append(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe8187e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENG', 'NZ', 'PAK', 'IND', 'AFG', 'AUS', 'BAN', 'AFG', 'BAN']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_bowler_team"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15d2288e",
   "metadata": {},
   "source": [
    "Q5. c)  NOT GOING WELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f542474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7122bedd",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    ".  a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    ". b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    ". c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b48463a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "page6= requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup6 = BeautifulSoup(page6.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3ac78a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India\n"
     ]
    }
   ],
   "source": [
    "# Q6. a)  'TOP_TEN ODI TEAM_WOMEN\n",
    "team=[]\n",
    "for i in soup6.find_all('span',class_= 'u-hide-phablet'):\n",
    "    #print(i.text)\n",
    "    team.append(i.text)\n",
    "team_name= team[0:10]\n",
    "print(team_name[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7631ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table= []\n",
    "for i in soup6.find_all('tr',class_= 'table-body'):\n",
    "    #print(i.text)\n",
    "    table.append(i.text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2460d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_rating= []\n",
    "team_matches= []\n",
    "team_points= []\n",
    "\n",
    "\n",
    "table\n",
    "for i in range(len(table)):\n",
    "    #print(table[i][-2])\n",
    "    team_points.append(table[i][-2])\n",
    "    #print(table[i][-1])\n",
    "    team_rating.append(table[i][-1])\n",
    "    #print(table[i][-3])\n",
    "    team_matches.append(table[i][-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2819bc9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32', '30', '29', '31', '30', '12', '30', '8', '8', '8']\n",
      "['3,949', '3,531', '2,889', '3,019', '2,768', '930', '1,962', '384', '351', '0']\n",
      "['123', '118', '100', '97', '92', '78', '65', '48', '44', '0']\n"
     ]
    }
   ],
   "source": [
    "print(team_matches)\n",
    "print(team_points)\n",
    "print(team_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3e617d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q6. b),c)= top ten WOMEN ODI BATTING_PLAYER along with 'team' & 'rating'\n",
    "page6_ = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup66= BeautifulSoup(page6_.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7053595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping 'top-women-batting-ranking & women-allrounder-ranking'\n",
    "rank= []\n",
    "for i in soup66.find_all('td', class_= 'table-body__cell name'):\n",
    "    #print(i.text.split()[0:2])\n",
    "    rank.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "a713b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_women_player= []\n",
    "top_women_allrounder= []\n",
    "k=[]\n",
    "for i in range(len(rank)):\n",
    "    #print(rank[i][1:-1])\n",
    "    k.append(rank[i][1:-1])\n",
    "    \n",
    "top_women_player.append(k[0:9])\n",
    "top_women_allrounder.append(k[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8619fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('women-allrounder-player=',top_women_allrounder)\n",
    "#print('\\n top-women-player==', top_women_player)       #  ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a35584c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scrapping  \" TOP ODI WOMEN ALLROUNDER TEAM, RATING\"\n",
    "ranking=[]\n",
    "for i in soup66.find_all('tr', class_= 'table-body'):\n",
    "   # print(i.text.split())\n",
    "    ranking.append(i.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d5e6ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = []\n",
    "te = []\n",
    "for i in range(len(ranking)):\n",
    "    ra.append(ranking[i][-1])\n",
    "    te.append(ranking[i][-2])\n",
    "    \n",
    "top_women_player_rating = ra[0:9]\n",
    "top_women_player_team = te[0:9]\n",
    "women_allrounder_rating = ra[-9:]\n",
    "women_allrounder_team = te[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a140e7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " top_women_player_rating== ['750', '748', '713', '710', '701', '681', '669', '659', '642']\n",
      "\n",
      "  top_women_player_team== ['ENG', 'AUS', 'SA', 'AUS', 'AUS', 'NZ', 'IND', 'ENG', 'AUS']\n",
      "\n",
      " women_allrounder_rating== ['374', '338', '338', '335', '269', '249', '245', '223', '221']\n",
      "\n",
      " women_allrounder_team== ['AUS', 'WI', 'SA', 'NZ', 'AUS', 'IND', 'AUS', 'SA', 'ENG']\n"
     ]
    }
   ],
   "source": [
    "print('\\n top_women_player_rating==', top_women_player_rating)\n",
    "print('\\n  top_women_player_team==', top_women_player_team)\n",
    "print('\\n women_allrounder_rating==', women_allrounder_rating)\n",
    "print('\\n women_allrounder_team==', women_allrounder_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922adc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "48c7bc39",
   "metadata": {},
   "source": [
    "Q7 =  Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    ". headline   .timeline  . newslink             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "94f82550",
   "metadata": {},
   "outputs": [],
   "source": [
    "page8 = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup8 = BeautifulSoup(page8.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "210c0080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Min Ago\n"
     ]
    }
   ],
   "source": [
    "# scrapping data \" TIME  &  NEWS HEADLINE\"\n",
    "time= []\n",
    "for i in soup8.find_all('time', class_ = 'LatestNews-timestamp'):\n",
    "    #print(i.text)\n",
    "    time.append(i.text)\n",
    "print(time[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0fccc800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student loan forgiveness 'not a problem that concerns the wealthy,' Schumer says \n"
     ]
    }
   ],
   "source": [
    "headline = []\n",
    "for i in soup8.find_all('a', class_ = 'LatestNews-headline'):\n",
    "    #print(i.text)\n",
    "    headline.append(i.text)\n",
    "print(headline[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1fc8f01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.cnbc.com/2022/06/22/investing-club-heres-what-9-companies-in-our-portfolio-are-working-on-to-profit-from-the-metaverse.html\n"
     ]
    }
   ],
   "source": [
    "news_url= []\n",
    "for i in soup8.find_all('a', class_='LatestNews-headline' ):\n",
    "    #print(i['href'])\n",
    "    news_url.append(i['href'])\n",
    "print(news_url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2444b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 ccompleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d486d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0fda893e",
   "metadata": {},
   "source": [
    "Q8 = 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days. \n",
    "== Scrape below mentioned details :\n",
    " 1. paper title, 2.Author , 3.Published date , 4.Paper Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "9d216cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "page8= requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "e67c733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup8 = BeautifulSoup(page8.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "466c5f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict-based search for optimal multi-agent pathfinding\n"
     ]
    }
   ],
   "source": [
    "# scrapping all Articles list data\n",
    "\n",
    "Articles= []\n",
    "for i in soup8.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    Articles.append(i.text)\n",
    "print(Articles[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "5f05c28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August 1998\n"
     ]
    }
   ],
   "source": [
    "# scrapping data ,in which date Artical download ,\n",
    "Published_date= []\n",
    "for i in soup8.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    Published_date.append(i.text)\n",
    "print(Published_date[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d0ed74bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prakken, Henry, Sartor, Giovanni \n"
     ]
    }
   ],
   "source": [
    "# scrapping data \"Article's Author name\"\n",
    "\n",
    "Author= []\n",
    "for i in soup8.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    Author.append(i.text)\n",
    "print(Author[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "3ff8dc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sciencedirect.com/science/article/pii/S0004370221000862\n"
     ]
    }
   ],
   "source": [
    "# Scrapping  data \" Article's URL\" \n",
    "url= []\n",
    "for i in soup8.find_all('a', class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    url.append(i['href'])\n",
    "print(url[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05163508",
   "metadata": {},
   "outputs": [],
   "source": [
    "###3  Q8. complete"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd1dd56f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0099721d",
   "metadata": {},
   "source": [
    "Q9.  Write a python program to scrape mentioned details from dineout.co.in :\n",
    ". restaurant name\n",
    ". cuisine  ,  .location   , . rating\n",
    ". image URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279feba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page9= requests.get('https://www.dineout.co.in/delhi-restaurants/value-for-money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36e787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup9 = BeautifulSoup(page9.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7906c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping '' restaurant location'' data\n",
    "location= []\n",
    "for i in soup9.find_all('div', class_= 'restnt-loc ellipsis' ):\n",
    "#    print(i.text)\n",
    "    location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc824435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping ''image url'' data \n",
    "image_URL = []\n",
    "for i in soup9.find_all('img', class_ ='no-img'):\n",
    "#    print(i['data-src'])\n",
    "    image_URL.append(i['data-src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fe4e3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Out Of The Box Courtyard', 'Ghoomar Traditional Thali Restaurant', 'Khandani Rajdhani', 'Blues']\n"
     ]
    }
   ],
   "source": [
    "# scrapping '' RESTAURANT NAME'' data\n",
    "restaurant_name= []\n",
    "for i in soup9.find_all('a', class_ =\"restnt-name ellipsis\"):\n",
    "#    print(i.text)\n",
    "    restaurant_name.append(i.text)\n",
    "print(restaurant_name[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5faa1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['North', 'Indian,', 'Mediterranean,', 'Chinese,', 'Italian'], ['North', 'Indian,', 'Rajasthani'], ['Gujarati,', 'Rajasthani,', 'North', 'Indian']]\n"
     ]
    }
   ],
   "source": [
    "# scrapping  '' RESTAURANT CUISINE name ''  data\n",
    "cuisine_name= []\n",
    "for i in soup9.find_all('span', class_ = 'double-line-ellipsis'):\n",
    "#    print(i.text.split()[6:])\n",
    "    cuisine_name.append(i.text.split()[6:])\n",
    "print(cuisine_name[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c58e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '4.1', '4', '4.2', '4.3']\n"
     ]
    }
   ],
   "source": [
    "# scrapping 'rating' data\n",
    "rating= []\n",
    "for i in soup9.find_all('div', class_ = \"restnt-rating rating-4\"):\n",
    "#    print(i.text)\n",
    "    rating.append(i.text)\n",
    "print(rating[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Q9. complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00529c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d1c94739",
   "metadata": {},
   "source": [
    "Q10=  10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    ".  Rank ,  .Publication,  .h5_index,  .h5_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25aabb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page10= requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdfd47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup10= BeautifulSoup(page10.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7850c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# scrapping google top scholar (  RANK's DATA  )\n",
    "\n",
    "rank= []\n",
    "for i in soup10.find_all('td', class_= 'gsc_mvt_p'):\n",
    "    n= i.text\n",
    "    rank.append(n)\n",
    "    \n",
    "print(len(rank))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d86b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# SCRAPPING DATA TOP SCHOLAR ( PUBLICATION NAMES )\n",
    "\n",
    "publication= []\n",
    "for i in soup10.find_all('td',class_= 'gsc_mvt_t'):\n",
    "    n=i.text\n",
    "    publication.append(n)\n",
    "    \n",
    "print(len(publication))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41ac0bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# SCRAPPING DATA h5_index and h5_median\n",
    "\n",
    "h=[]\n",
    "for i in soup10.find_all('td', class_= 'gsc_mvt_n'):\n",
    "    #print(i.text)\n",
    "    h.append(i.text)\n",
    "\n",
    "print(len(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d081740",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  scrapping h5_index data\n",
    "h5_index= []\n",
    "for i in range(0,200,2):\n",
    "    h5=h[i]\n",
    "    h5_index.append(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1121b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  scrapping h5_median data\n",
    "h5_median= []\n",
    "for i in range(1,201,2):\n",
    "    h5=h[i]\n",
    "    h5_median.append(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "642cf343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 , 100\n"
     ]
    }
   ],
   "source": [
    "print(len(h5_median),',',len(h5_index), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assignment complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
